
### Setup for Ollama

First, follow these instructions to set up and run a local Ollama instance:

- Download and install Ollama onto the available supported platforms (including Windows Subsystem for Linux aka WSL, macOS, and Linux)
macOS users can install via Homebrew with `brew install ollama` and start with `brew services start ollama`
- Fetch available LLM model via `ollama pull llama3.2`

